# Example of decision tree classifier

Google colab code:

https://colab.research.google.com/drive/1baCL6bmpb6ADLvLhFqwjNazquSGz6rC0?hl=en#scrollTo=hShah0VzHqwj

A decision tree is a decision support tool that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.

A decision tree is a flowchart-like structure in which each internal node represents a "test" on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules.

In decision analysis, a decision tree and the closely related influence diagram are used as a visual and analytical decision support tool, where the expected values (or expected utility) of competing alternatives are calculated.

A decision tree consists of three types of nodes:

1. Decision nodes 
2. Chance nodes 
3. End nodes 

![image](https://user-images.githubusercontent.com/43271573/137578188-09353747-f750-408c-aecd-3744933689a8.png)
